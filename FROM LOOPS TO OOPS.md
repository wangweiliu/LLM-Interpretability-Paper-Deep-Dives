# 论文精读调研

> 调研论文，并撰写下列内容
> 调研人：王伟柳

## 论文名称

名称：FROM LOOPS TO OOPS: FALLBACK BEHAVIORS OF
LANGUAGE MODELS UNDER UNCERTAINTY

链接：https://neurips.cc/virtual/2024/105336
## 基础信息

| 工作类别（攻击/可解释性分析/防御）       | 具体信息 |
| ---------------------------------------- | -------- |
| 模态（llm/推理llm/多模态）               |llm          |
| 时间（年份，arxiv文章需要月份，如25.11） |2024          |
| 刊物                                     |NeurIPS         |
| 首作者                                   |Maor Ivgi|
| 首作单位                                 |Blavatnik School of Computer Science, Tel Aviv University|
| 研究目标（输出增长/循环输出）                |循环输出          |
| 一句话方法概括                            |论文提出将重复生成、文本退化和幻觉统一视为模型在面对认知不确定性时的Fallback Behaviors，并揭示了随着模型能力增强，这些行为遵循从简单重复到复杂幻觉的演变规律|

## 方法概述

> 1. 自己阅读文章，不要使用ai总结，有看不懂的地方可以问模型，但是不能依靠模型阅读。
> 2. 方法概述不需要过于详细的形式化公式，使用语言表述，以【研究目标-研究手段】为线路进行总结。其中研究手段可以稍作展开，分点按步骤进行撰写。

### 研究目标
旨在探究llm在面临认知不确定性时，产生的fallback行为（重复、退化文本、幻觉）之间的内在联系和演变规律

### 研究手段
构建诱导不确定性的实验环境，设计了特定的数据集（TRIVIAFACTS, FAKEQAMPARI），通过强制模型生成其知识范围之外的内容来人为构造不确定性场景

## 实验效果
> 概括介绍实验结果，主要关注作者采取的实验指标、baseline和实际效果。
> 
实验指标：行为分类统计（统计生成内容中正确事实、幻觉事实、重复事实的比例）、ShiftScore（用于量化单次生成过程中，行为转变的顺序）、DiversityScore（用于衡量生成文本的多样性）

随着模型变强（参数增加、经过指令微调），其在不确定情况下的回退行为会从简单的重复转变为复杂的幻觉。在单次长文本生成中，随着不确定性增加，行为呈现反向演变，正确回答->幻觉->退化文本->序列重复（ShiftScore指标表明）。虽然随机采样可以有效减少重复和退化文本，但它显著增加了幻觉的比例。

## 引用论文

> 关注论文的`Introduction`、`related work`和`experiment setup`部分，追踪查找作者列举的**关于资源消耗和输出长度异常**的相关研究。列出其基本信息

| 论文题目 | 发表刊物 | 时间 | 一句话概括研究领域和方向（例：llm 可解释性+防御） |
| -------- | -------- | ---- | ------------------------------------------------- |



## 被引论文
> 在 https://scholar.google.com/ 和 上进行当前论文搜索，以此查看所有引用本论文的研究，提取其中**关于资源消耗和输出长度异常**的相关研究。列出其基本信息

| 论文题目 | 发表刊物 | 时间 | 一句话概括研究领域和方向（例：llm 可解释性+防御） |
| -------- | -------- | ---- | ------------------------------------------------- |
|Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing|emnlp|2024|llm机器翻译重复与语言不匹配问题+模型编辑（神经元干预）优化|
|Demystify Verbosity Compensation Behavior of Large Language Models|UncertaiNLP (Workshop)|2025|llm啰嗦/冗余生成行为分析+基于不确定性的缓解策略|